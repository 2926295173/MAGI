{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading C:\\Users\\JUNQIC~1\\AppData\\Local\\Temp\\tmp8slkm1fm\\list.json: 0.00%|                | 0.00MB/0.00MB [00:00<?]D:\\Software\\Anaconda3\\lib\\site-packages\\tqdm\\std.py:533: TqdmWarning: clamping frac to range [0, 1]\n",
      "  full_bar = Bar(frac,\n",
      "Downloading C:\\Users\\JUNQIC~1\\AppData\\Local\\Temp\\tmp8slkm1fm\\list.json: 898.25%|██████████| 0.00MB/0.00MB [00:00<00:00]\n",
      "Downloading C:\\Users\\JUNQIC~1\\AppData\\Local\\Temp\\tmp8slkm1fm\\ghv9-2.json: 100.00%|████| 132.65MB/132.65MB [00:08<00:00]\n",
      "magi_dataset.magi_dataset - INFO - Loaded 5000 repos from C:\\Users\\Junqi Chen\\AppData\\Local\\Temp\\tmp8slkm1fm\\ghv9-2.json\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "from stackapi import StackAPI\n",
    "from magi_dataset import *\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "\n",
    "# create ./data dir to cache dataset\n",
    "if not os.path.exists('./data'):\n",
    "    os.mkdir(\"./data\")\n",
    "\n",
    "# github dataset with 5000 repo\n",
    "github_dataset = GitHubDataset(\n",
    "    empty = False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proxy Engine (ignore what it does)\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "useful_proxy = {}\n",
    "i = 0\n",
    "\n",
    "def get_proxy():\n",
    "    proxies = [] # proxies poll\n",
    "    proxy = {} # now using proxy\n",
    "    \n",
    "    # load the proxies poll\n",
    "    proxies.clear()\n",
    "    url='https://sslproxies.org/'\n",
    "    response=requests.get(url)\n",
    "    soup=BeautifulSoup(response.content, 'lxml')\n",
    "    for item in soup.select('table[class=\"table table-striped table-bordered\"] > tbody > tr'):\n",
    "        try:\n",
    "            proxies.append({'ip': item.select('td')[0].get_text(), \n",
    "                            'port': item.select('td')[1].get_text()})\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # random select a current proxy\n",
    "    global i\n",
    "    if i >= len(proxies):\n",
    "        i = 0\n",
    "    randomIP = proxies[i]['ip']\n",
    "    randomPort = proxies[i]['port']\n",
    "    proxy =  {\"https\": f\"https://{randomIP}:{randomPort}\"}\n",
    "    i += 1\n",
    "    print(f\"now using proxy {proxy}\")\n",
    "    return proxy\n",
    "\n",
    "def repeat_get():\n",
    "    global useful_proxy\n",
    "    if useful_proxy:\n",
    "        current_proxy = useful_proxy\n",
    "    else:\n",
    "        current_proxy = get_proxy()\n",
    "    SITE = None\n",
    "    while not SITE:\n",
    "        try:\n",
    "            SITE = StackAPI('stackoverflow', proxy=current_proxy)\n",
    "            if not useful_proxy and SITE: # useful_proxy is empty and response get\n",
    "                useful_proxy = current_proxy\n",
    "        except:\n",
    "            print(f\"discard current useful proxy {current_proxy}.\")\n",
    "            useful_proxy = {}\n",
    "            current_proxy = get_proxy()\n",
    "    return SITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now using proxy {'https': 'https://18.166.72.199:8081'}\n",
      "discard current useful proxy {'https': 'https://18.166.72.199:8081'}.\n",
      "now using proxy {'https': 'https://112.217.162.5:3128'}\n",
      "discard current useful proxy {'https': 'https://112.217.162.5:3128'}.\n",
      "now using proxy {'https': 'https://103.28.100.11:3128'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SITE Error occurs with dataset length 0.\n",
      "Saving current data...\n",
      "discard current useful proxy {'https': 'https://103.28.100.11:3128'}.\n",
      "now using proxy {'https': 'https://18.166.72.199:8081'}\n",
      "discard current useful proxy {'https': 'https://18.166.72.199:8081'}.\n",
      "now using proxy {'https': 'https://112.217.162.5:3128'}\n",
      "discard current useful proxy {'https': 'https://112.217.162.5:3128'}.\n",
      "now using proxy {'https': 'https://103.28.100.11:3128'}\n",
      "discard current useful proxy {'https': 'https://103.28.100.11:3128'}.\n",
      "now using proxy {'https': 'https://188.0.147.102:3128'}\n",
      "discard current useful proxy {'https': 'https://188.0.147.102:3128'}.\n",
      "now using proxy {'https': 'https://31.186.239.245:8080'}\n",
      "discard current useful proxy {'https': 'https://31.186.239.245:8080'}.\n",
      "now using proxy {'https': 'https://104.223.135.178:10000'}\n",
      "discard current useful proxy {'https': 'https://104.223.135.178:10000'}.\n",
      "now using proxy {'https': 'https://117.251.103.186:8080'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|███████████████████████████████████████████████████████████████████████████▏  | 4816/5000 [18:15<08:34,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SITE Error occurs with dataset length 300.\n",
      "Saving current data...\n",
      "discard current useful proxy {'https': 'https://117.251.103.186:8080'}.\n",
      "now using proxy {'https': 'https://5.9.149.118:40000'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████████▍  | 4834/5000 [22:01<29:07, 10.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SITE Error occurs with dataset length 18.\n",
      "Saving current data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████████████████████████████████████████████████████████████████████▍  | 4835/5000 [23:43<1:45:01, 38.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SITE Error occurs with dataset length 1.\n",
      "Saving current data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████████▋  | 4851/5000 [24:44<04:47,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SITE Error occurs with dataset length 16.\n",
      "Saving current data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [32:56<00:00,  2.53it/s]\n"
     ]
    }
   ],
   "source": [
    "stackoverflow_dataset = []\n",
    "SITE = repeat_get()\n",
    "\n",
    "for i, repo in enumerate(tqdm(github_dataset)):\n",
    "    if i < 4516:\n",
    "        continue\n",
    "    repo_name = repo.name\n",
    "    repo_dict = {\"name\":repo_name, \"item\":[]}\n",
    "    url = f'https://github.com/{repo_name}'\n",
    "\n",
    "    # Search the question list given the url and sort based on activity\n",
    "    try:\n",
    "        question_list = SITE.fetch('search/excerpts', url = url, sort='activity', order='desc')\n",
    "    except:\n",
    "        print(f\"SITE Error occurs with dataset length {len(stackoverflow_dataset)}.\")\n",
    "        print(\"Saving current data...\")\n",
    "        # Save to json file when error occurs\n",
    "        filename = './data/stackoverflow_dataset.json'\n",
    "        if os.path.isfile(filename) is False:\n",
    "            with open(filename, 'w') as outfile:\n",
    "                json.dump(stackoverflow_dataset, outfile, indent=2)\n",
    "        else:\n",
    "            with open(filename) as infile:\n",
    "                data = json.load(infile)\n",
    "            data += stackoverflow_dataset\n",
    "            with open(filename, 'w') as outfile:\n",
    "                json.dump(data, outfile, indent=2)\n",
    "        # Handle SITE Error\n",
    "        SITE = repeat_get()\n",
    "        question_list = SITE.fetch('search/excerpts', url = url, sort='activity', order='desc')\n",
    "        stackoverflow_dataset = []\n",
    "\n",
    "    # Store the top 5 questions of each question to the dictionary \n",
    "    for question in question_list['items'][:5]:\n",
    "        question_title = question['title']\n",
    "        repo_dict['item'].append(question_title)\n",
    "    stackoverflow_dataset.append(repo_dict)\n",
    "#     time.sleep(0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './data/stackoverflow_dataset.json'\n",
    "data = []\n",
    "with open(filename) as infile:\n",
    "    temp = json.load(infile)\n",
    "    \n",
    "for i, d in enumerate(temp):\n",
    "    if i < 135:\n",
    "        data.append(d)\n",
    "    else:\n",
    "        data += d\n",
    "        \n",
    "with open('./data/stackoverflow_real.json', 'w') as outfile:\n",
    "    json.dump(data, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "70f3c9c5f530effdc6a80dbad78b3cafea2afa458216aedd385384b265543c30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
